{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "u8gwPUj3Owuz",
        "Ed25P60XOzdf",
        "31IzUIw_55Ot",
        "nUExziEW55eb",
        "tZ9Q6kLg55my",
        "XsgcTLHR555V",
        "3fGOat3clUL0",
        "UiT1ifx1k9f3",
        "5Xes6SjM56ST",
        "ZGvYMid056ZH",
        "1tux53Nm2uHz"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7316cd53dd4940489dd817e1f01780da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eaccc79abf5e4e90a713cd3700f537f0",
              "IPY_MODEL_fa798e5e51aa44799974f85c0c812e96",
              "IPY_MODEL_62133b38087a48daa373ffe05ffce7a5"
            ],
            "layout": "IPY_MODEL_05e5ba67a3f3451aad9a37d93e97b0cb"
          }
        },
        "eaccc79abf5e4e90a713cd3700f537f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c422c7274dd2442da98696d4982ae8cf",
            "placeholder": "​",
            "style": "IPY_MODEL_60845301999f4754a3e4fc822850b90e",
            "value": "Map: 100%"
          }
        },
        "fa798e5e51aa44799974f85c0c812e96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a4540fc258e4804b55266e5907387cd",
            "max": 11873,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_680438c57474437db5dc323378783b64",
            "value": 11873
          }
        },
        "62133b38087a48daa373ffe05ffce7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02a5fbdcca2e4655a27654cf2c12768e",
            "placeholder": "​",
            "style": "IPY_MODEL_054d0a553f10479186b0a56dfe1c9fdc",
            "value": " 11873/11873 [00:21&lt;00:00, 1090.11 examples/s]"
          }
        },
        "05e5ba67a3f3451aad9a37d93e97b0cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c422c7274dd2442da98696d4982ae8cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60845301999f4754a3e4fc822850b90e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a4540fc258e4804b55266e5907387cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "680438c57474437db5dc323378783b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02a5fbdcca2e4655a27654cf2c12768e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "054d0a553f10479186b0a56dfe1c9fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "162509f33a804d4b8eaf9ff52e1433a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8624c91eb82a42b987eeada68afcd051",
              "IPY_MODEL_21489b423ecf401f888f2a2d5b63b413",
              "IPY_MODEL_8da2917b54f24c2e966638a0cccd1815"
            ],
            "layout": "IPY_MODEL_8fb87b2499f94f4c9eacdb785b9b0df5"
          }
        },
        "8624c91eb82a42b987eeada68afcd051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0d067d561784235990e2d31b3c1f7a0",
            "placeholder": "​",
            "style": "IPY_MODEL_01bf65cb779342a9bbe4c12eae0e8d38",
            "value": "100%"
          }
        },
        "21489b423ecf401f888f2a2d5b63b413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fc0a34c187c482eb0e3363d096f19f8",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_988bd5a46e8949e7abd3ab64d5fe8631",
            "value": 100
          }
        },
        "8da2917b54f24c2e966638a0cccd1815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a32a2dcd1354513b78f96cc32f0f483",
            "placeholder": "​",
            "style": "IPY_MODEL_8253fb98a08b41b9bf13b7d949b7e2f9",
            "value": " 100/100 [07:33&lt;00:00,  4.46s/it]"
          }
        },
        "8fb87b2499f94f4c9eacdb785b9b0df5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0d067d561784235990e2d31b3c1f7a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01bf65cb779342a9bbe4c12eae0e8d38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fc0a34c187c482eb0e3363d096f19f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988bd5a46e8949e7abd3ab64d5fe8631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a32a2dcd1354513b78f96cc32f0f483": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8253fb98a08b41b9bf13b7d949b7e2f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reshalfahsi/qa-gpt2-lora/blob/master/Question_Answering_GPT_2_PEFT_LoRA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question-Answering using GPT-2's PEFT with LoRA**"
      ],
      "metadata": {
        "id": "6ObWltxB533p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Important Libraries**"
      ],
      "metadata": {
        "id": "VqL8FTPH6C6r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Install**"
      ],
      "metadata": {
        "id": "u8gwPUj3Owuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -LsSf https://astral.sh/uv/install.sh | sh"
      ],
      "metadata": {
        "id": "iTynQrK4749q",
        "outputId": "32d98344-cad4-4fae-8d17-c1ea91a387d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading uv 0.5.21 x86_64-unknown-linux-gnu\n",
            "no checksums to verify\n",
            "installing to /root/.local/bin\n",
            "  uv\n",
            "  uvx\n",
            "everything's installed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uv pip install -q --no-cache-dir --system transformers peft datasets\n",
        "!uv pip install -q --no-cache-dir --system bitsandbytes accelerate\n",
        "!uv pip install -q --no-cache-dir --system huggingface-hub\n",
        "!uv pip install -q --no-cache-dir --system evaluate"
      ],
      "metadata": {
        "id": "gD6mhBuR8M_q"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import**"
      ],
      "metadata": {
        "id": "Ed25P60XOzdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers import TrainingArguments, Trainer, BitsAndBytesConfig\n",
        "from transformers import DataCollatorForLanguageModeling, pipeline\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "from datasets import load_dataset\n",
        "from evaluate import load as load_evaluate\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import warnings\n",
        "import random\n",
        "import torch\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "QIlZcpxy54K2"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Configuration**"
      ],
      "metadata": {
        "id": "31IzUIw_55Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"experiment\", exist_ok=True)\n",
        "os.makedirs(\"experiment/model\", exist_ok=True)\n",
        "EXPERIMENT_DIR = \"experiment/\""
      ],
      "metadata": {
        "id": "lWoj3eU0rrVp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"gpt2\"\n",
        "FINETUNED_MODEL = os.path.join(EXPERIMENT_DIR, \"model\")\n",
        "DATASET_NAME = \"squad_v2\"\n",
        "METRIC_NAME = \"bleu\"\n",
        "MAX_ORDER = 1"
      ],
      "metadata": {
        "id": "YOiVQl1v55S5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LORA_DROPOUT = 2e-1\n",
        "LORA_RANK = 4\n",
        "LORA_ALPHA = 8"
      ],
      "metadata": {
        "id": "zfwPDGyk7yAP"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_PER_DEVICE = 5\n",
        "GRADIENT_ACCUMULATION_STEP = 10"
      ],
      "metadata": {
        "id": "ZkJ_vnH270dk"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LEARNING_RATE = 5e-5\n",
        "SAMPLE_TEST_SIZE = 100"
      ],
      "metadata": {
        "id": "HdBf_9Bv71xi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EVAL_STEP = int(2e2)\n",
        "LOGGING_STEP = int(2e2)\n",
        "SAVE_STEP = int(1e2)\n",
        "WARMUP_STEP = int(1e2)\n",
        "MAX_STEP = int(1.2e3)"
      ],
      "metadata": {
        "id": "rHyrEAEK7272"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_TOKEN = 128\n",
        "MAX_LENGTH = 1024"
      ],
      "metadata": {
        "id": "EwoCs7Oe74ue"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ],
      "metadata": {
        "id": "OQRDLLX0CK6_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset**"
      ],
      "metadata": {
        "id": "f_L1zmLe55Wz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load**"
      ],
      "metadata": {
        "id": "nUExziEW55eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset_orig = load_dataset(DATASET_NAME)"
      ],
      "metadata": {
        "id": "Dslp3Ng-xnnp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "print(\n",
        "    f\"The max model length is {tokenizer.model_max_length} for this model, \"\n",
        "    \"although the actual embedding size for GPT small is 768\"\n",
        ")\n",
        "print(\n",
        "    \"The beginning of sequence \"\n",
        "    f\"token {tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id)} \"\n",
        "    f\"token has the id {tokenizer.bos_token_id}\"\n",
        ")\n",
        "print(\n",
        "    \"The end of \"\n",
        "    f\"sequence token {tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id)} \"\n",
        "    f\"has the id {tokenizer.eos_token_id}\"\n",
        ")\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\n",
        "    \"The padding \"\n",
        "    f\"token {tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id)} \"\n",
        "    f\"has the id {tokenizer.pad_token_id}\"\n",
        ")"
      ],
      "metadata": {
        "id": "ye5rwzhu55bH",
        "outputId": "80c7f783-061a-4ec8-e156-7489bd14a6a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max model length is 1024 for this model, although the actual embedding size for GPT small is 768\n",
            "The beginning of sequence token <|endoftext|> token has the id 50256\n",
            "The end of sequence token <|endoftext|> has the id 50256\n",
            "The padding token <|endoftext|> has the id 50256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Utils**"
      ],
      "metadata": {
        "id": "tZ9Q6kLg55my"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(context, question, answer):\n",
        "    if len(answer[\"text\"]) < 1:\n",
        "        answer = \"Cannot Find Answer\"\n",
        "    else:\n",
        "        index = random.randint(0, len(answer[\"text\"])-1)\n",
        "        answer = answer[\"text\"][index]\n",
        "\n",
        "    prompt_template = (\n",
        "        f\"CONTEXT:\\n{context}\\n\"\n",
        "        f\"\\nQUESTION:\\n{question}\\n\"\n",
        "        f\"\\nANSWER:\\n{answer}\"\n",
        "    )\n",
        "\n",
        "    return prompt_template\n",
        "\n",
        "\n",
        "qa_dataset = qa_dataset_orig.map(\n",
        "    lambda samples: tokenizer(\n",
        "        create_prompt(\n",
        "            samples[\"context\"],\n",
        "            samples[\"question\"],\n",
        "            samples[\"answers\"],\n",
        "        ),\n",
        "        max_length=MAX_LENGTH,\n",
        "        truncation=True,\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "i3tLx0n555iu",
        "outputId": "88f11575-2fc2-49df-dc91-91838dce3820",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "7316cd53dd4940489dd817e1f01780da",
            "eaccc79abf5e4e90a713cd3700f537f0",
            "fa798e5e51aa44799974f85c0c812e96",
            "62133b38087a48daa373ffe05ffce7a5",
            "05e5ba67a3f3451aad9a37d93e97b0cb",
            "c422c7274dd2442da98696d4982ae8cf",
            "60845301999f4754a3e4fc822850b90e",
            "0a4540fc258e4804b55266e5907387cd",
            "680438c57474437db5dc323378783b64",
            "02a5fbdcca2e4655a27654cf2c12768e",
            "054d0a553f10479186b0a56dfe1c9fdc"
          ]
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/11873 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7316cd53dd4940489dd817e1f01780da"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model**"
      ],
      "metadata": {
        "id": "evjfc6eX55uj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load**"
      ],
      "metadata": {
        "id": "XsgcTLHR555V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quantization_config,\n",
        ")"
      ],
      "metadata": {
        "id": "SoGcchip55y4"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Info**"
      ],
      "metadata": {
        "id": "3fGOat3clUL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(base_model.named_parameters())\n",
        "\n",
        "print(\n",
        "    'The GPT-2 model has {:} different named parameters.\\n'.format(len(params))\n",
        ")\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:2]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[2:14]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-2:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "id": "CWt8qF_9lTih",
        "outputId": "7920472e-b86b-48b7-d8a6-46c299119ff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPT-2 model has 148 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "transformer.wte.weight                                  (50257, 768)\n",
            "transformer.wpe.weight                                   (1024, 768)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "transformer.h.0.ln_1.weight                                   (768,)\n",
            "transformer.h.0.ln_1.bias                                     (768,)\n",
            "transformer.h.0.attn.c_attn.weight                       (2304, 768)\n",
            "transformer.h.0.attn.c_attn.bias                             (2304,)\n",
            "transformer.h.0.attn.c_proj.weight                        (768, 768)\n",
            "transformer.h.0.attn.c_proj.bias                              (768,)\n",
            "transformer.h.0.ln_2.weight                                   (768,)\n",
            "transformer.h.0.ln_2.bias                                     (768,)\n",
            "transformer.h.0.mlp.c_fc.weight                          (3072, 768)\n",
            "transformer.h.0.mlp.c_fc.bias                                (3072,)\n",
            "transformer.h.0.mlp.c_proj.weight                        (768, 3072)\n",
            "transformer.h.0.mlp.c_proj.bias                               (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "transformer.ln_f.weight                                       (768,)\n",
            "transformer.ln_f.bias                                         (768,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PEFT with LoRA**"
      ],
      "metadata": {
        "id": "UiT1ifx1k9f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=LORA_RANK,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    target_modules=[\n",
        "        \"c_attn\",\n",
        "        \"c_fc\",\n",
        "        \"c_proj\",\n",
        "    ],\n",
        "    lora_dropout=LORA_DROPOUT,\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "model = get_peft_model(base_model, lora_config)"
      ],
      "metadata": {
        "id": "_IBtbfGJk9lW"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training**"
      ],
      "metadata": {
        "id": "5Xes6SjM56ST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=qa_dataset[\"train\"],\n",
        "    eval_dataset=qa_dataset[\"validation\"],\n",
        "    args=TrainingArguments(\n",
        "        output_dir=EXPERIMENT_DIR,\n",
        "        per_device_train_batch_size=BATCH_PER_DEVICE,\n",
        "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEP,\n",
        "        eval_strategy=\"steps\",\n",
        "        eval_steps=EVAL_STEP,\n",
        "        save_steps=SAVE_STEP,\n",
        "        warmup_steps=WARMUP_STEP,\n",
        "        max_steps=MAX_STEP,\n",
        "        logging_steps=LOGGING_STEP,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        fp16=True,\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        "    data_collator=DataCollatorForLanguageModeling(\n",
        "        tokenizer,\n",
        "        mlm=False,\n",
        "    ),\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "LQ6RgQR_jqpZ",
        "outputId": "4809a9d1-ef8b-46cb-d183-c8775a083720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1200' max='1200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1200/1200 1:02:50, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>34.655200</td>\n",
              "      <td>3.053641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>31.650100</td>\n",
              "      <td>2.994655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>31.296400</td>\n",
              "      <td>2.975799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>31.106300</td>\n",
              "      <td>2.967888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>31.149200</td>\n",
              "      <td>2.964367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>31.063300</td>\n",
              "      <td>2.963042</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1200, training_loss=31.820098063151043, metrics={'train_runtime': 3772.961, 'train_samples_per_second': 15.903, 'train_steps_per_second': 0.318, 'total_flos': 8351521283635200.0, 'train_loss': 31.820098063151043, 'epoch': 0.4604051565377532})"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(FINETUNED_MODEL)\n",
        "tokenizer.save_pretrained(FINETUNED_MODEL)"
      ],
      "metadata": {
        "id": "flHsQT2F81R-",
        "outputId": "46e0ef43-4c08-484e-d7c4-18d035fd674b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('experiment/model/tokenizer_config.json',\n",
              " 'experiment/model/special_tokens_map.json',\n",
              " 'experiment/model/vocab.json',\n",
              " 'experiment/model/merges.txt',\n",
              " 'experiment/model/added_tokens.json',\n",
              " 'experiment/model/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Testing**"
      ],
      "metadata": {
        "id": "ZGvYMid056ZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PeftModel.from_pretrained(base_model, FINETUNED_MODEL)\n",
        "tokenizer = AutoTokenizer.from_pretrained(FINETUNED_MODEL)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "qa_metric = load_evaluate(METRIC_NAME)\n",
        "predictions = list()\n",
        "references = list()\n",
        "\n",
        "SEED = int(np.random.randint(2147483647))\n",
        "test_data = qa_dataset_orig[\"validation\"].shuffle(seed=SEED).select(\n",
        "    range(SAMPLE_TEST_SIZE)\n",
        ")\n",
        "\n",
        "\n",
        "for qa_data in tqdm(test_data):\n",
        "\n",
        "    answer = qa_data['answers']\n",
        "\n",
        "    if len(answer[\"text\"]) < 1:\n",
        "        answer = [\"Cannot Find Answer\"]\n",
        "\n",
        "    references.append(answer)\n",
        "\n",
        "    context = qa_data['context']\n",
        "    question = qa_data['question']\n",
        "\n",
        "    template = (\n",
        "        f\"CONTEXT:\\n{context}\\n\"\n",
        "        f\"\\nQUESTION:\\n{question}\\n\"\n",
        "        \"\\nANSWER:\\n\"\n",
        "    )\n",
        "\n",
        "    pred_index = len(template)\n",
        "\n",
        "    input = tokenizer(\n",
        "        template,\n",
        "        return_tensors='pt',\n",
        "        return_token_type_ids=False,\n",
        "    )\n",
        "    input = input.to(device='cuda' if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    with torch.cuda.amp.autocast():\n",
        "        model.enable_adapter_layers()\n",
        "        output_tokens_qa = model.generate(\n",
        "            **input,\n",
        "            max_new_tokens=MAX_TOKEN,\n",
        "            pad_token_id=tokenizer.pad_token_type_id,\n",
        "        )\n",
        "\n",
        "    answer = tokenizer.decode(\n",
        "        output_tokens_qa[0],\n",
        "        skip_special_tokens=True,\n",
        "    ).replace(template, '')\n",
        "    try:\n",
        "        answer = answer[:answer.find(\"\\n\\nANSWER:\\n\")]\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    predictions.append(answer)"
      ],
      "metadata": {
        "id": "r4LTcqPQ4qM9",
        "outputId": "f2cc63f6-ea56-4762-8894-054b589f35f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "162509f33a804d4b8eaf9ff52e1433a2",
            "8624c91eb82a42b987eeada68afcd051",
            "21489b423ecf401f888f2a2d5b63b413",
            "8da2917b54f24c2e966638a0cccd1815",
            "8fb87b2499f94f4c9eacdb785b9b0df5",
            "a0d067d561784235990e2d31b3c1f7a0",
            "01bf65cb779342a9bbe4c12eae0e8d38",
            "9fc0a34c187c482eb0e3363d096f19f8",
            "988bd5a46e8949e7abd3ab64d5fe8631",
            "3a32a2dcd1354513b78f96cc32f0f483",
            "8253fb98a08b41b9bf13b7d949b7e2f9"
          ]
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "162509f33a804d4b8eaf9ff52e1433a2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = qa_metric.compute(\n",
        "    predictions=predictions,\n",
        "    references=references,\n",
        "    max_order=MAX_ORDER,\n",
        ")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "5LGqAQCWhCaK",
        "outputId": "32a0960e-b4d8-44b0-cb20-24a25c33b605",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu': 0.16666666666666669, 'precisions': [0.16666666666666666], 'brevity_penalty': 1.0, 'length_ratio': 3.029126213592233, 'translation_length': 624, 'reference_length': 206}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Inference**"
      ],
      "metadata": {
        "id": "hyJ9D9JK56hP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Utils**"
      ],
      "metadata": {
        "id": "1tux53Nm2uHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = PeftModel.from_pretrained(base_model, FINETUNED_MODEL)\n",
        "tokenizer = AutoTokenizer.from_pretrained(FINETUNED_MODEL)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "EcXys5U456lj"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_inference(context, question):\n",
        "\n",
        "    template = (\n",
        "        f\"CONTEXT:\\n{context}\\n\"\n",
        "        f\"\\nQUESTION:\\n{question}\\n\"\n",
        "        \"\\nANSWER:\\n\"\n",
        "    )\n",
        "\n",
        "    # turn the input into tokens\n",
        "    input = tokenizer(\n",
        "        template,\n",
        "        return_tensors='pt',\n",
        "        return_token_type_ids=False,\n",
        "    )\n",
        "    # move the tokens onto the GPU, for inference\n",
        "    input = input.to(device='cuda' if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # make an inference\n",
        "    with torch.cuda.amp.autocast():\n",
        "        model.enable_adapter_layers()\n",
        "        output_tokens_qa = model.generate(\n",
        "            **input,\n",
        "            max_new_tokens=MAX_TOKEN,\n",
        "            pad_token_id=tokenizer.pad_token_type_id,\n",
        "        )\n",
        "\n",
        "    result = tokenizer.decode(output_tokens_qa[0], skip_special_tokens=True)\n",
        "    try:\n",
        "        result = result[\n",
        "            :result.find(\n",
        "                \"\\n\\nANSWER:\\n\",\n",
        "                result.find(\"\\n\\nANSWER:\\n\") + 1,\n",
        "            )\n",
        "        ]\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    result = result.replace(\n",
        "        \"CONTEXT:\", \"**CONTEXT:**\"\n",
        "    ).replace(\n",
        "        \"QUESTION:\", \"**QUESTION:**\"\n",
        "    ).replace(\n",
        "        \"ANSWER:\", \"**ANSWER:**\"\n",
        "    )\n",
        "\n",
        "    # display results\n",
        "    display(Markdown(\"\\n# Question-Answering with GPT-2 \\n\"))\n",
        "    display(\n",
        "        Markdown(\n",
        "            (result)\n",
        "        )\n",
        "    )"
      ],
      "metadata": {
        "id": "F1MXw5Jd2uN0"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Run**"
      ],
      "metadata": {
        "id": "t_A-t7Cd2wPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONTEXT = \"The trophy doesn't fit into the brown suitcase because it's too small.\" # @param {type:\"string\"}\n",
        "QUESTION = \"What is too small?\"  # @param {type:\"string\"}\n"
      ],
      "metadata": {
        "id": "N72F2ocK56tg",
        "cellView": "form"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ANSWER:\n",
        "make_inference(CONTEXT, QUESTION)"
      ],
      "metadata": {
        "id": "V4GLRA9L6_H5",
        "outputId": "bb25763e-ed6d-4277-97f8-d3d0f378b8c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n# Question-Answering with GPT-2 \n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**CONTEXT:**\nThe trophy doesn't fit into the brown suitcase because it's too small.\n\n**QUESTION:**\nWhat is too small?\n\n**ANSWER:**\nbrown suitcase."
          },
          "metadata": {}
        }
      ]
    }
  ]
}